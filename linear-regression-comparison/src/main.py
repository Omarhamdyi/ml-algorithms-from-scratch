from  load_data import load_data_scaled 
from normal_equation import normal_equation
from scikit_imp import scikit_implementation
from gradient_descent import gradient_descent
import numpy as np

if __name__ == "__main__":
    X , y = load_data_scaled()
    y_pred0 , W_neq , cost_neq = normal_equation(X,y)
    y_pred1 , W_sk  , cost_sk  = scikit_implementation(X,y)
    y_pred2 , W_gd  , cost_gd  = gradient_descent(X,y,step_size = 0.1 , max_iter = 10000)
    

    print(cost_neq , cost_gd , cost_neq)
    # print(W_neq)
    # print(W_sk)  
    # print(W_gd)    








# at iter = 10000 and step_size = 0.001
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [0.67294329 0.96776934 0.6703993  0.55454243 0.42433534 0.65091369
#  0.4370773  0.83908413 0.99851559]


# at iter = 10000 and step_size = 0.01
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [ 0.84033908  5.222912    0.84219228  0.62216963  0.39888275  0.65485588
#   0.40166895 -0.73483878 -0.54876134]

# at iter = 10000 and step_size = 0.1
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [  3.72961166   6.33214009   0.48122468 -15.13916237  21.76021606
#   -0.1418736   -4.70531325  -3.96456829  -4.3625181 ]
# [ 3.46904075  5.608185    0.58193581  0.51505836  0.97072581  0.48714267
#   0.07316374 -3.65842993 -3.94199966]0.07316374 -3.65842993 -3.94199966]